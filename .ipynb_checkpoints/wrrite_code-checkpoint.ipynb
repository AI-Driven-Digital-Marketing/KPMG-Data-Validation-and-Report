{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bea6d271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main_page.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Data_Quality.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from pandas_profiling import ProfileReport\n",
    "from pandas_profiling.utils.cache import cache_zipped_file\n",
    "from streamlit_pandas_profiling import st_profile_report\n",
    "\n",
    "\n",
    "st.markdown(\"# Data Quality Check\")\n",
    "st.sidebar.markdown(\"# Data Quality Check\")\n",
    "tab1, tab2, tab3, tab4, tab5 = st.tabs([\"Transaction\", \"New Customer\", \"Customer Demo\", 'CustomerAddress', 'Takeaways'])\n",
    "\n",
    "# progress_text = \"Operation in progress. Please wait.\"\n",
    "# my_bar = st.progress(0, text=progress_text)\n",
    "# for percent_complete in range(100):\n",
    "#     time.sleep(0.1)\n",
    "#     my_bar.progress(percent_complete + 1, text=progress_text)\n",
    "\n",
    "    \n",
    "st.success('Your DataOverview Report is Completed', icon=\"✅\")\n",
    "\n",
    "\n",
    "@st.cache_resource \n",
    "def profiling_transaction(sheet):\n",
    "    df = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name= sheet)\n",
    "    if sheet != 'CustomerDemographic':\n",
    "        df.columns = df.iloc[0,:]\n",
    "        df  = df.iloc[1:,:]\n",
    "        df = df.loc[:,~df.columns.isna()]\n",
    "\n",
    "\n",
    "\n",
    "    profile = ProfileReport(\n",
    "        df, title=\"Profile Report of the Transaction Sheet\", explorative=True\n",
    "    )\n",
    "    return profile\n",
    "\n",
    "with tab1:\n",
    "    profile = profiling_transaction('Transactions')\n",
    "    st_profile_report(profile)\n",
    "\n",
    "    \n",
    "with tab2:\n",
    "    profile = profiling_transaction('NewCustomerList')\n",
    "    st_profile_report(profile)    \n",
    "    \n",
    "with tab3:\n",
    "    profile = profiling_transaction('CustomerDemographic')\n",
    "    st_profile_report(profile) \n",
    "    \n",
    "with tab4:\n",
    "    profile = profiling_transaction('CustomerAddress')\n",
    "    st_profile_report(profile) \n",
    "    \n",
    "with tab5:\n",
    "    '''\n",
    "    ### Takeaway & Insights\n",
    "    1. **Data accuracy:**\n",
    "    Inconsistencies and inaccuracies in the data. For data birth, a lot of record has date of birth Over 120 years old and the max one even have 174 years old.\n",
    "    It seems that this table have long time historical data which is updated with time goes by, but without check the death situation.\n",
    "    2. **Data completeness:** Some column in the dataset where contains null values.(It seems need data cleaning)\n",
    "    \n",
    "    3. **Data consistency:** Some tables have incorrect data types, for this demographic table, the DOB should be timestamp, but the checkresult shows that it contain some non-numeric value.(We need conduct some data cleaning and data type transformation before do visualization and ml)\n",
    "    4. **Data timelines:** transaction dataset seems good, and it has no problems with data currency.\n",
    "    5. **Data validity:** Some data points in the dataset are invalid, for example, one record in date of\n",
    "    birth in the Customer Demographic sheet making them 174 years old, which is not be used, need go back to data source.\n",
    "    6. **Data uniqueness:** By conduct quality checking, we could not find any duplicate data in the dataset.\n",
    "        '''\n",
    "\n",
    "    \n",
    "    st.write('### Suggestions')\n",
    "    st.write('- Regular Data Audits: Conducting periodic assessments to eliminate invalid data and ensure the uniqueness of the information.')\n",
    "    st.write('- Clear Data Collection Guidelines: Establishing explicit protocols for collecting data.')\n",
    "    st.write('- Cross-Checking Procedures: Implementing cross-referencing techniques between different data fields.')\n",
    "    st.write('- Consistent Naming Conventions: Setting clear guidelines for naming data fields across the organization.')\n",
    "    st.write('- Data Validation: Implementing checks to verify the accuracy of specific data types in designated columns.')\n",
    "    \n",
    "\n",
    "\n",
    "st.download_button(\n",
    "  'Download  Report',\n",
    "  data='This is some text',\n",
    "  help='Click  to get you own  insights!'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46ebd5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pages/page_2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pages/page_2.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "st.markdown(\"# Page 2 ❄️\")\n",
    "st.sidebar.markdown(\"Page 2\")\n",
    "\n",
    "#Shit hole begin\n",
    "transactions = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='Transactions',header=1)\n",
    "NewCustomer = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='NewCustomerList',header=1)\n",
    "Demographic  = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='CustomerDemographic')\n",
    "CustomerAddress = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='CustomerAddress',header=1)\n",
    "\n",
    "\n",
    "Transactions = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name= 'Transactions')\n",
    "Transactions.columns = Transactions.iloc[0,:]\n",
    "Transactions  = Transactions.iloc[1:,:]\n",
    "Transactions.dropna(subset=['product_first_sold_date'], inplace=True)\n",
    "Transactions.product_first_sold_date = Transactions.product_first_sold_date.apply(lambda x: datetime.fromtimestamp(x))\n",
    "Transactions.transaction_date = Transactions.transaction_date.astype('string')\n",
    "Transactions['transaction_month'] = Transactions.transaction_date.apply(lambda x: x[5:7])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# brand count\n",
    "st.write('- Each brand has different marketing strategy and target populations, their sales statistics are hence different.')\n",
    "st.write('- Understanding these difference is important when organizing any business activities.')\n",
    "\n",
    "Tran_counts = Transactions.groupby(['brand'],as_index=False)['list_price'].count()\n",
    "Tran_counts.columns = ['brand', 'count']\n",
    "# brand revenue\n",
    "Tran_brand = Transactions.groupby(['brand'],as_index=False)[['list_price','standard_cost']].sum()\n",
    "Tran_brand['profit'] = Tran_brand['list_price'] - Tran_brand['standard_cost']\n",
    "Tran_brand = Tran_brand.merge(Tran_counts, on = ['brand'])\n",
    "Tran_brand['list_price_avg'] = Tran_brand['list_price'] / Tran_brand['count']\n",
    "Tran_brand['profit_avg'] = Tran_brand['profit'] / Tran_brand['count']\n",
    "Tran_brand['profit_rate'] = 1- Tran_brand['standard_cost']/Tran_brand['list_price']\n",
    "st.dataframe(Tran_brand.style.highlight_max(axis=0, color = 'lightblue'))\n",
    "\n",
    "\n",
    "#---------------Bing Start -----------------------------\n",
    "#Brand Selling proportion\n",
    "brand_sell = transactions.groupby('brand').count().reset_index().iloc[:,0:2]\n",
    "brand_sell.columns = ['brand','sells_num']\n",
    "\n",
    "\n",
    "labels = list(brand_sell['brand'])\n",
    "data = list(brand_sell['sells_num'])\n",
    "\n",
    "#Creating fig and ax\n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "\n",
    "#define Seaborn color palette to use\n",
    "colors = sns.color_palette('pastel')[0:6]\n",
    "\n",
    "#create pie chart\n",
    "plt.pie(data, labels = labels, colors = colors, autopct='%.0f%%')\n",
    "plt.tight_layout()\n",
    "\n",
    "ax.set_title('')\n",
    "st.title('Brand Selling Proportion')\n",
    "st.pyplot(fig)\n",
    "\n",
    "#Insight\n",
    "st.write('- Brands are cutting market evenly. Solex is taking biggest cut with number of 21%, followed by Giant Bicycles and WeareA2B.')\n",
    "\n",
    "#---------------Bing End -----------------------------\n",
    "\n",
    "\n",
    "#---------------Bing Online vs Brand Start -----------------------------\n",
    "\n",
    "#Online order\n",
    "st.write('## Brands Online Sells Analysis')\n",
    "brand_online_sold = pd.DataFrame(transactions[transactions['online_order']==1.0]['brand'].value_counts()).reset_index()\n",
    "brand_offline_sold = pd.DataFrame(transactions[transactions['online_order']==0]['brand'].value_counts()).reset_index()\n",
    "\n",
    "cols = ['brand','online_sold','offline_sold']\n",
    "brand_online_vs_offline = brand_online_sold.merge(brand_offline_sold,how='inner',on = 'index').set_axis(cols,axis=1)\n",
    "st.dataframe(brand_online_vs_offline)\n",
    "\n",
    "st.write('For all the brands, online proportion and offline are closed, which proves the importance of off line store in Bike market.')\n",
    "\n",
    "#---------------Bing Online vs Brand End -------------------------------\n",
    "\n",
    "# Customer payment count\n",
    "CustomerAddress = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name= 'CustomerAddress')\n",
    "CustomerAddress.columns = CustomerAddress.iloc[0,:]\n",
    "CustomerAddress  = CustomerAddress.iloc[1:,:]\n",
    "Customer_counts = Transactions.groupby(['customer_id'],as_index=False)['list_price'].count()\n",
    "Customer_counts.columns = ['customer_id', 'bill_count']\n",
    "# Customer payment revenue\n",
    "Cutomer_brand = Transactions.groupby(['customer_id'],as_index=False)[['list_price','standard_cost']].sum()\n",
    "Cutomer_brand['profit'] = Cutomer_brand['list_price'] - Cutomer_brand['standard_cost']\n",
    "Cutomer_brand = Cutomer_brand.merge(Customer_counts, on = ['customer_id'])\n",
    "Cutomer_brand['list_price_avg'] = Cutomer_brand['list_price'] / Cutomer_brand['bill_count']\n",
    "Cutomer_brand['profit_avg'] = Cutomer_brand['profit'] / Cutomer_brand['bill_count']\n",
    "Cutomer_brand['profit_rate'] = 1- Cutomer_brand['standard_cost']/Cutomer_brand['list_price']\n",
    "Cutomer_brand = Cutomer_brand.merge(CustomerAddress[['customer_id', 'property_valuation']], on = 'customer_id')\n",
    "st.write('- Pay closely attention to customer purchase frequency as we want to keep our customers and expand their consumptions.')\n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "Cutomer_brand.hist(['bill_count'] , ax = ax)\n",
    "ax.set_title('')\n",
    "st.title('Purchase Frequency Counts')\n",
    "st.pyplot(fig)\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize = (10,6))\n",
    "Cutomer_brand.plot.scatter(['list_price_avg'], ['profit_avg'], \n",
    "                           figsize = (16,9),\n",
    "                           c = Cutomer_brand.property_valuation,\n",
    "                           ax = ax1\n",
    "                           )\n",
    "ax1.set_title('')\n",
    "st.title('Price versus Profit')\n",
    "st.pyplot(fig1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41050272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pages/page_3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pages/page_3.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "st.markdown(\"# Page 3 🎉\")\n",
    "st.sidebar.markdown(\"Page 3 🎉\")\n",
    "import streamlit as st\n",
    "\n",
    "# Add a selectbox to the sidebar:\n",
    "add_selectbox = st.sidebar.selectbox(\n",
    "    'How would you like to be contacted?',\n",
    "    ('Email', 'Home phone', 'Mobile phone')\n",
    ")\n",
    "\n",
    "# Add a slider to the sidebar:\n",
    "add_slider = st.sidebar.slider(\n",
    "    'Select a range of values',\n",
    "    0.0, 100.0, (25.0, 75.0)\n",
    ")\n",
    "\n",
    "@st.experimental_memo\n",
    "def load_data(url):\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n",
    "df = load_data(\"https://github.com/plotly/datasets/raw/master/uber-rides-data1.csv\")\n",
    "st.dataframe(df)\n",
    "\n",
    "st.button(\"Rerun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f67f8d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile environment.yml\n",
    "name: STEnv\n",
    "dependencies:\n",
    "  - pandas-profiling\n",
    "  - numpy\n",
    "  - pandas\n",
    "  - matplotlib\n",
    "  - seaborn\n",
    "  - openpyxl\n",
    "  - pip\n",
    "  - pip:\n",
    "    - streamlit-pandas-profiling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19ba70ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'streamlit' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!streamlit run Data_Quality.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d4fa27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STEnv",
   "language": "python",
   "name": "stenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
