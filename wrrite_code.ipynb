{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bea6d271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Data_Quality.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Data_Quality.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from pandas_profiling import ProfileReport\n",
    "from pandas_profiling.utils.cache import cache_zipped_file\n",
    "from streamlit_pandas_profiling import st_profile_report\n",
    "\n",
    "\n",
    "st.markdown(\"# Data Quality Check\")\n",
    "st.sidebar.markdown(\"# Data Quality Check\")\n",
    "tab1, tab2, tab3, tab4, tab5 = st.tabs([\"Transaction\", \"New Customer\", \"Customer Demo\", 'CustomerAddress', 'Takeaways'])\n",
    "\n",
    "# progress_text = \"Operation in progress. Please wait.\"\n",
    "# my_bar = st.progress(0, text=progress_text)\n",
    "# for percent_complete in range(100):\n",
    "#     time.sleep(0.1)\n",
    "#     my_bar.progress(percent_complete + 1, text=progress_text)\n",
    "\n",
    "    \n",
    "st.success('Your DataOverview Report is Completed', icon=\"‚úÖ\")\n",
    "\n",
    "\n",
    "@st.cache_resource \n",
    "def profiling_transaction(sheet):\n",
    "    df = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name= sheet)\n",
    "    if sheet != 'CustomerDemographic':\n",
    "        df.columns = df.iloc[0,:]\n",
    "        df  = df.iloc[1:,:]\n",
    "        df = df.loc[:,~df.columns.isna()]\n",
    "\n",
    "\n",
    "\n",
    "    profile = ProfileReport(\n",
    "        df, title=\"Profile Report of the Transaction Sheet\", explorative=True\n",
    "    )\n",
    "    \n",
    "    return profile\n",
    "\n",
    "with tab1:\n",
    "    profile = profiling_transaction('Transactions')\n",
    "    st_profile_report(profile)\n",
    "    st.download_button(\n",
    "      'Download  Report',\n",
    "      data=profile.to_html(),\n",
    "        file_name = 'Transactions.html',\n",
    "      help='Click  to get you own insights!'\n",
    ")\n",
    "\n",
    "    \n",
    "with tab2:\n",
    "    profile = profiling_transaction('NewCustomerList')\n",
    "    st_profile_report(profile)    \n",
    "    st.download_button(\n",
    "      'Download  Report',\n",
    "      data=profile.to_html(),\n",
    "        file_name = 'NewCustomerList.html',\n",
    "      help='Click  to get you own insights!'\n",
    ")\n",
    "    \n",
    "with tab3:\n",
    "    profile = profiling_transaction('CustomerDemographic')\n",
    "    st_profile_report(profile) \n",
    "    st.download_button(\n",
    "      'Download  Report',\n",
    "      data=profile.to_html(),\n",
    "        file_name = 'CustomerDemographic.html',\n",
    "      help='Click  to get you own insights!'\n",
    ")    \n",
    "with tab4:\n",
    "    profile = profiling_transaction('CustomerAddress')\n",
    "    st_profile_report(profile) \n",
    "    st.download_button(\n",
    "      'Download  Report',\n",
    "      data=profile.to_html(),\n",
    "        file_name = 'CustomerAddress.html',\n",
    "      help='Click  to get you own insights!'\n",
    ")       \n",
    "with tab5:\n",
    "    '''\n",
    "    ### General Data Issue\n",
    "    1. **Data accuracy:**\n",
    "    Inconsistencies and inaccuracies in the data. For data birth, a lot of record has date of birth Over 120 years old and the max one even have 174 years old.\n",
    "    It seems that this table have long period historical data which is updated with time goes by, but without check the death situation.\n",
    "    2. **Data completeness:** Some column in the dataset contain null values.\n",
    "    3. **Data consistency:** Some tables have incorrect data types, for this demographic table, the DOB should be timestamp, but the checkresult shows that it contain some non-numeric value.(We need conduct some data cleaning and data type transformation before do visualization and ml)\n",
    "    4. **Data timelines:** transaction dataset seems good, and it has no problems with data currency.\n",
    "    5. **Data validity:** Some data points in the dataset are invalid, for example, one record in date of\n",
    "    birth in the Customer Demographic sheet making them 174 years old, which is not be used, need go back to data source.\n",
    "    6. **Data uniqueness:** By conduct quality checking, we could not find any duplicate data in the dataset.\n",
    "        '''\n",
    "\n",
    "    \n",
    "    st.write('### Suggestions')\n",
    "    st.write('- Regular Data Audits: Conducting periodic assessments to eliminate invalid data and ensure the uniqueness of the information.')\n",
    "    st.write('- Clear Data Collection Guidelines: Establishing explicit protocols for collecting data.')\n",
    "    st.write('- Cross-Checking Procedures: Implementing cross-referencing techniques between different data fields.')\n",
    "    st.write('- Consistent Naming Conventions: Setting clear guidelines for naming data fields across the organization.')\n",
    "    st.write('- Data Validation: Implementing checks to verify the accuracy of specific data types in designated columns.')\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ebd5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pages/Insight.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pages/Insight.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#st.set_page_config(layout=\"wide\")\n",
    "st.markdown(\"# Insight\")\n",
    "st.sidebar.markdown(\"Insight\")\n",
    "\n",
    "#Shit hole begin\n",
    "transactions = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='Transactions',header=1)\n",
    "NewCustomer = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='NewCustomerList',header=1)\n",
    "Demographic  = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='CustomerDemographic')\n",
    "CustomerAddress = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='CustomerAddress',header=1)\n",
    "\n",
    "\n",
    "Transactions = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name= 'Transactions')\n",
    "Transactions.columns = Transactions.iloc[0,:]\n",
    "Transactions  = Transactions.iloc[1:,:]\n",
    "Transactions.dropna(subset=['product_first_sold_date'], inplace=True)\n",
    "Transactions.product_first_sold_date = Transactions.product_first_sold_date.apply(lambda x: datetime.fromtimestamp(x))\n",
    "Transactions.transaction_date = Transactions.transaction_date.astype('string')\n",
    "Transactions['transaction_month'] = Transactions.transaction_date.apply(lambda x: x[5:7])\n",
    "Transactions.product_id = Transactions.product_id.astype('string')\n",
    "product_summary = Transactions.groupby(['product_id'],as_index=False).aggregate(\n",
    "            {'list_price':'mean',\n",
    "             'brand':'first',\n",
    "            'standard_cost':'mean',\n",
    "            'transaction_id':'count'})\n",
    "product_summary.sort_values(by=['list_price','standard_cost'],inplace=True,ascending=[False, True])\n",
    "product_summary = product_summary.rename({'transaction_id': 'count'}, axis=1)\n",
    "brands_name = Transactions.brand.unique()\n",
    "chosen_brand = st.selectbox(\n",
    "    'Choose brand here:',\n",
    "    brands_name)\n",
    "\n",
    "brand_fig, ax = plt.subplots(1,2,figsize=(16, 9))\n",
    "ax[0].yaxis.tick_right()\n",
    "sns.barplot(data=product_summary[product_summary.brand == chosen_brand], \n",
    "              x=\"list_price\", \n",
    "              y=\"product_id\", \n",
    "                  ax = ax[0],\n",
    "                  color = 'green'\n",
    "             )\n",
    "sns.barplot(data=product_summary[product_summary.brand == chosen_brand], \n",
    "              x=\"standard_cost\", \n",
    "              y=\"product_id\", \n",
    "                  ax = ax[0],\n",
    "                  color = 'orange'\n",
    "                \n",
    "             )\n",
    "sns.barplot(data=product_summary[product_summary.brand == chosen_brand], \n",
    "              x=\"count\", \n",
    "              y=\"product_id\", \n",
    "                  ax = ax[1],\n",
    "                  color = 'lightblue'\n",
    "             )\n",
    "ax[0].legend(['price','cost'],fontsize=14)\n",
    "ax[0].invert_xaxis()\n",
    "leg = ax[0].get_legend()\n",
    "leg.legendHandles[0].set_color('green')\n",
    "leg.legendHandles[1].set_color('orange')\n",
    "ax[1].legend(['Count'], fontsize = 14)\n",
    "leg1 = ax[1].get_legend()\n",
    "leg1.legendHandles[0].set_color('lightblue')\n",
    "st.pyplot(brand_fig)\n",
    "# brand count\n",
    "st.write('- Each brand has different marketing strategy and target populations, their sales statistics are hence different.')\n",
    "st.write('- Understanding these difference is important when organizing any business activities.')\n",
    "\n",
    "Tran_counts = Transactions.groupby(['brand'],as_index=False)['list_price'].count()\n",
    "Tran_counts.columns = ['brand', 'count']\n",
    "# brand revenue\n",
    "Tran_brand = Transactions.groupby(['brand'],as_index=False)[['list_price','standard_cost']].sum()\n",
    "Tran_brand['profit'] = Tran_brand['list_price'] - Tran_brand['standard_cost']\n",
    "Tran_brand = Tran_brand.merge(Tran_counts, on = ['brand'])\n",
    "Tran_brand['list_price_avg'] = Tran_brand['list_price'] / Tran_brand['count']\n",
    "Tran_brand['profit_avg'] = Tran_brand['profit'] / Tran_brand['count']\n",
    "Tran_brand['profit_rate'] = 1- Tran_brand['standard_cost']/Tran_brand['list_price']\n",
    "st.dataframe(Tran_brand.style.highlight_max(axis=0, color = 'lightblue'))\n",
    "\n",
    "\n",
    "#---------------Bing Start -----------------------------\n",
    "#Brand Selling proportion\n",
    "brand_sell = transactions.groupby('brand').count().reset_index().iloc[:,0:2]\n",
    "brand_sell.columns = ['brand','sells_num']\n",
    "\n",
    "\n",
    "labels = list(brand_sell['brand'])\n",
    "data = list(brand_sell['sells_num'])\n",
    "\n",
    "#Creating fig and ax\n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "\n",
    "#define Seaborn color palette to use\n",
    "colors = sns.color_palette('pastel')[0:6]\n",
    "\n",
    "#create pie chart\n",
    "plt.pie(data, labels = labels, colors = colors, autopct='%.0f%%')\n",
    "plt.tight_layout()\n",
    "\n",
    "ax.set_title('')\n",
    "st.write('## Brand Selling Proportion')\n",
    "st.pyplot(fig)\n",
    "\n",
    "#Insight\n",
    "st.write('- Brands are cutting market evenly.')\n",
    "st.write('- Solex is taking biggest cut with number of 21%, followed by Giant Bicycles and WeareA2B with 17%')\n",
    "\n",
    "#---------------Bing End -----------------------------\n",
    "\n",
    "\n",
    "#---------------Bing Online vs Brand Start -----------------------------\n",
    "\n",
    "#Online order\n",
    "st.write('## Brands Online Sells Analysis')\n",
    "brand_online_sold = pd.DataFrame(transactions[transactions['online_order']==1.0]['brand'].value_counts()).reset_index()\n",
    "brand_offline_sold = pd.DataFrame(transactions[transactions['online_order']==0]['brand'].value_counts()).reset_index()\n",
    "\n",
    "cols = ['brand','online_sold','offline_sold']\n",
    "brand_online_vs_offline = brand_online_sold.merge(brand_offline_sold,how='inner',on = 'index').set_axis(cols,axis=1)\n",
    "st.dataframe(brand_online_vs_offline)\n",
    "\n",
    "st.write('- Online shopping proportion showing similar patterns. All taking around 50% proportions.')\n",
    "st.write('- Offline store is still taking a huge place under the impact of online shopping trend. Offline experience still cant fully replace by convinience.')\n",
    "\n",
    "#---------------Bing Online vs Brand End -------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#---------------Bing Average Profit of brands in different class Start -------------------------------\n",
    "\n",
    "st.write('## Average Profit of brands in different class')\n",
    "transactions['profit'] = transactions['list_price'] - transactions['standard_cost']\n",
    "\n",
    "profit = transactions.groupby(['brand','product_class']).mean()[['list_price','standard_cost','profit']]\n",
    "#profit = transactions.groupby(['brand']).mean()[['profit']]\n",
    "\n",
    "profit.reset_index(inplace=True)\n",
    "my_order = ['low','medium','high']\n",
    "\n",
    "profit['product_class'] = profit['product_class'].astype('category')\n",
    "profit['product_class'].cat.reorder_categories(my_order, inplace= True)\n",
    "profit.sort_values(['brand','product_class'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "sns.barplot(data = profit, x = 'brand',y = 'profit',hue='product_class',)\n",
    "plt.tight_layout()\n",
    "st.pyplot(fig)\n",
    "st.write('- OHM and Solex have amazing profit on low class products.')\n",
    "st.write('- Trek and Weare A2B have advantages on middle class products.')\n",
    "st.write('- Giant and Nocro are not competitive in profits compared to their opposite. With similar share of markets, company is making much less revenue.')\n",
    "\n",
    "\n",
    "\n",
    "#---------------Bing Average Profit of brands in different class End -------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#---------------Bing Rich Customer Industry Start -------------------------------\n",
    "\n",
    "st.write('## Valuable Customers Industry Source')\n",
    "Rich_Ind = Demographic[(Demographic['wealth_segment'] == 'Affluent Customer')|(Demographic['wealth_segment'] == 'High Net Worth')].groupby('job_industry_category').count().reset_index().iloc[:,0:2]\n",
    "\n",
    "labels = list(Rich_Ind['job_industry_category'])\n",
    "data = list(Rich_Ind['customer_id'])\n",
    "\n",
    "#define Seaborn color palette to use\n",
    "colors = sns.color_palette('pastel')[0:10]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "\n",
    "#create pie chart\n",
    "plt.pie(data, labels = labels, colors = colors, autopct='%.0f%%')\n",
    "plt.tight_layout()\n",
    "\n",
    "ax.set_title('')\n",
    "st.title('')\n",
    "st.pyplot(fig)\n",
    "\n",
    "st.write('- Proportion of valuable customers is having similer pattern with all-customers industry pattern.')\n",
    "st.write('- No strong evidence indicating that customers from certain areas having higher willingness to pay.')\n",
    "\n",
    "#---------------Bing Rich Customer Industry End -------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Customer payment count\n",
    "CustomerAddress = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name= 'CustomerAddress')\n",
    "CustomerAddress.columns = CustomerAddress.iloc[0,:]\n",
    "CustomerAddress  = CustomerAddress.iloc[1:,:]\n",
    "Customer_counts = Transactions.groupby(['customer_id'],as_index=False)['list_price'].count()\n",
    "Customer_counts.columns = ['customer_id', 'bill_count']\n",
    "# Customer payment revenue\n",
    "Cutomer_brand = Transactions.groupby(['customer_id'],as_index=False)[['list_price','standard_cost']].sum()\n",
    "Cutomer_brand['profit'] = Cutomer_brand['list_price'] - Cutomer_brand['standard_cost']\n",
    "Cutomer_brand = Cutomer_brand.merge(Customer_counts, on = ['customer_id'])\n",
    "Cutomer_brand['list_price_avg'] = Cutomer_brand['list_price'] / Cutomer_brand['bill_count']\n",
    "Cutomer_brand['profit_avg'] = Cutomer_brand['profit'] / Cutomer_brand['bill_count']\n",
    "Cutomer_brand['profit_rate'] = 1- Cutomer_brand['standard_cost']/Cutomer_brand['list_price']\n",
    "Cutomer_brand = Cutomer_brand.merge(CustomerAddress[['customer_id', 'property_valuation']], on = 'customer_id')\n",
    "\n",
    "#Verbal\n",
    "st.write('')\n",
    "\n",
    "Cutomer_brand\n",
    "st.write('- Pay closely attention to customer purchase frequency as we want to keep our customers and expand their consumptions.')\n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "Cutomer_brand.hist(['bill_count'] , ax = ax)\n",
    "ax.set_title('')\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_ylabel('Customer counts')\n",
    "st.write('## Purchase Frequency Counts')\n",
    "st.pyplot(fig)\n",
    "st.write('- Most customers bought 5 products for this year. Probably indicating high user stickness')\n",
    "fig1, ax1 = plt.subplots(figsize = (10,6))\n",
    "Cutomer_brand.plot.scatter(['list_price_avg'], ['profit_avg'], \n",
    "                           figsize = (16,9),\n",
    "                           c = Cutomer_brand.property_valuation,\n",
    "                           ax = ax1\n",
    "                           )\n",
    "ax1.set_title('')\n",
    "ax1.set_xlabel('Average Purchase Price')\n",
    "ax1.set_ylabel('Average Profit')\n",
    "st.write('## Price versus Profit')\n",
    "st.pyplot(fig1)\n",
    "st.write('- The deeper the color, the richer the customer.')\n",
    "st.write('- Part of luxury products having over 75% profit rate.')\n",
    "st.write('- Most purchase lie in range between 750 and 1500, which should be comfort zone for most buyer.')\n",
    "st.write('- No significant evidence showing wealthy customers prefer more expensive products.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41050272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pages/Introduction.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pages/Introduction.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "st.markdown(\"# KPMG Data Analysis Platform üéâ\")\n",
    "st.sidebar.markdown(\"Contact & Controllerüéâ\")\n",
    "import streamlit as st\n",
    "\n",
    "\n",
    "\n",
    "# Add a selectbox to the sidebar:\n",
    "add_selectbox = st.sidebar.selectbox(\n",
    "    'How would you like to be contacted?',\n",
    "    ('Email', 'Home phone', 'Mobile phone')\n",
    ")\n",
    "\n",
    "st.sidebar.text_area('Contact Infomation', \n",
    "                      'Please leave your contact information on here! You would get compelete report!!')\n",
    "\n",
    "# add mugshot to sidebar\n",
    "# mugshot = st.sidebar.camera_input(\n",
    "#   '## Create your mugshot for your own Report'\n",
    "# )\n",
    "# Add a slider to the sidebar:\n",
    "# add_slider = st.sidebar.slider(\n",
    "#     'Select a range of values',\n",
    "#     0.0, 100.0, (25.0, 75.0)\n",
    "# )\n",
    "#####################Main page###\n",
    "\n",
    "tab1, tab2, tab3 = st.tabs([\"Why us?\" , \"Solutions & Anticipations\", \"About this Platform\"])\n",
    "\n",
    "with tab1:\n",
    "    col1, col2 = st.columns(2,gap = \"medium\")\n",
    "    with col1:\n",
    "       st.image('src/IMG_5301 2.JPG',width = 400)\n",
    "\n",
    "    with col2:\n",
    "       st.markdown('## Why Us?')\n",
    "       '''\n",
    "       1. User-Friendly Interface: The platform features a user-friendly interface that allows users to easily visualize, manipulate, and explore their data, without requiring specialized technical skills.\n",
    "\n",
    "       2. Advanced Analytics: The platform includes advanced analytics capabilities, such as machine learning algorithms, predictive modeling, and statistical analysis, allowing users to uncover insights and make data-driven decisions.\n",
    "       \n",
    "       3. Scalability and Security: The platform is designed to be scalable and secure, ensuring that it can accommodate growing amounts of data and protect sensitive information.\n",
    "       '''\n",
    "    \n",
    "with tab2:\n",
    "    \n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "       st.markdown('## Solutions & Anticipations')\n",
    "       '''\n",
    "        1. **Deep understanding your data profile!**\n",
    "            KYC,KYB and Know your data!\n",
    "            \n",
    "        2. **Check your data Quality!**\n",
    "            Ensure your data quality from 6 dimensions and not be deceived!\n",
    "            \n",
    "        3. **Powerful Analytics tools!**\n",
    "           Analyze your data set in multiple dimensions and give you the most comprehensive adviceÔºÅ\n",
    "           \n",
    "        4. **Intelligent Suggestion! **\n",
    "            Intelligently provide valuable insights for your preprocessing procedure.\n",
    "            \n",
    "        5. **Visualization and Dashboard!**\n",
    "            Quick, colorful, informative dashboard to let you aim your target users.\n",
    "        '''\n",
    "\n",
    "    with col2:\n",
    "       st.image('src/IMG_5301 2.JPG')\n",
    "      \n",
    "\n",
    "\n",
    "with tab3:\n",
    "    \n",
    "    st.image(\"https://static.streamlit.io/examples/cat.jpg\")\n",
    "\n",
    "    '''\n",
    "    Your personal Report is here\n",
    "    '''\n",
    "#     st.image(mugshot, width=300)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# @st.experimental_memo\n",
    "# def load_data(url):\n",
    "#     df = pd.read_csv(url)\n",
    "#     return df\n",
    "\n",
    "# df = load_data(\"https://github.com/plotly/datasets/raw/master/uber-rides-data1.csv\")\n",
    "# st.dataframe(df)\n",
    "\n",
    "# st.button(\"Rerun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f67f8d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile environment.yml\n",
    "name: STEnv\n",
    "dependencies:\n",
    "  - pandas-profiling\n",
    "  - numpy\n",
    "  - pandas\n",
    "  - matplotlib\n",
    "  - seaborn\n",
    "  - openpyxl\n",
    "  - pip\n",
    "  - pip:\n",
    "    - streamlit-pandas-profiling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19ba70ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.1.158:8501\u001b[0m\n",
      "\u001b[0m\n",
      "2023-02-11 11:19:30.759 Pandas backend loaded 1.4.2\n",
      "2023-02-11 11:19:30.763 Numpy backend loaded 1.21.5\n",
      "2023-02-11 11:19:30.763 Pyspark backend NOT loaded\n",
      "2023-02-11 11:19:30.763 Python backend loaded\n",
      "/Users/laibinghui/Documents/GitHub/INFO-7374-DM-Project/pages/Insight.py:12: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  NewCustomer = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='NewCustomerList',header=1)\n",
      "/Users/laibinghui/Documents/GitHub/INFO-7374-DM-Project/pages/Insight.py:13: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  Demographic  = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='CustomerDemographic')\n",
      "/Users/laibinghui/Documents/GitHub/INFO-7374-DM-Project/pages/Insight.py:12: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  NewCustomer = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='NewCustomerList',header=1)\n",
      "/Users/laibinghui/Documents/GitHub/INFO-7374-DM-Project/pages/Insight.py:13: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  Demographic  = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='CustomerDemographic')\n",
      "/Users/laibinghui/Documents/GitHub/INFO-7374-DM-Project/pages/Insight.py:143: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  profit['product_class'].cat.reorder_categories(my_order, inplace= True)\n",
      "/Users/laibinghui/Documents/GitHub/INFO-7374-DM-Project/pages/Insight.py:12: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  NewCustomer = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='NewCustomerList',header=1)\n",
      "/Users/laibinghui/Documents/GitHub/INFO-7374-DM-Project/pages/Insight.py:13: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  Demographic  = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='CustomerDemographic')\n",
      "/Users/laibinghui/Documents/GitHub/INFO-7374-DM-Project/pages/Insight.py:143: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  profit['product_class'].cat.reorder_categories(my_order, inplace= True)\n",
      "/Users/laibinghui/Documents/GitHub/INFO-7374-DM-Project/pages/Insight.py:12: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  NewCustomer = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='NewCustomerList',header=1)\n",
      "/Users/laibinghui/Documents/GitHub/INFO-7374-DM-Project/pages/Insight.py:13: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  Demographic  = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='CustomerDemographic')\n",
      "/Users/laibinghui/Documents/GitHub/INFO-7374-DM-Project/pages/Insight.py:143: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  profit['product_class'].cat.reorder_categories(my_order, inplace= True)\n",
      "/Users/laibinghui/Documents/GitHub/INFO-7374-DM-Project/pages/Insight.py:12: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  NewCustomer = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='NewCustomerList',header=1)\n",
      "/Users/laibinghui/Documents/GitHub/INFO-7374-DM-Project/pages/Insight.py:13: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  Demographic  = pd.read_excel('KPMG_VI_New_raw_data_update_final.xlsx',sheet_name='CustomerDemographic')\n",
      "/Users/laibinghui/Documents/GitHub/INFO-7374-DM-Project/pages/Insight.py:143: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n",
      "  profit['product_class'].cat.reorder_categories(my_order, inplace= True)\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run Data_Quality.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STEnv",
   "language": "python",
   "name": "stenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
